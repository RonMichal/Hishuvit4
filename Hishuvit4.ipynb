{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nom0ICQL6HED"
      },
      "source": [
        "# Imports and setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-02T13:16:21.172303Z",
          "iopub.status.busy": "2022-10-02T13:16:21.171788Z",
          "iopub.status.idle": "2022-10-02T13:16:22.089537Z",
          "shell.execute_reply": "2022-10-02T13:16:22.088254Z",
          "shell.execute_reply.started": "2022-10-02T13:16:21.172251Z"
        },
        "id": "KTn2D6TR6HEJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install copulae\n",
        "!pip install skfeature-chappers\n",
        "!pip install scikit-posthocs\n",
        "\n",
        "from copulae import EmpiricalCopula, pseudo_obs\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "from math import fabs\n",
        "from sklearn.pipeline import make_pipeline, Pipeline\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, matthews_corrcoef, roc_auc_score, auc, average_precision_score, precision_recall_curve\n",
        "from sklearn.model_selection import LeavePOut, LeaveOneOut, KFold, StratifiedKFold, GridSearchCV\n",
        "from sklearn.feature_selection import f_classif, SelectFdr, RFE, VarianceThreshold, SelectKBest\n",
        "from sklearn.svm import SVR, SVC\n",
        "from skfeature.function.information_theoretical_based.MRMR import mrmr\n",
        "from skfeature.function.similarity_based.reliefF import reliefF\n",
        "from timeit import default_timer as time\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from os.path import exists, isdir\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from google.colab import drive\n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "from scipy.stats import friedmanchisquare, wilcoxon\n",
        "from scikit_posthocs import posthoc_nemenyi_friedman as posthoc\n",
        "from collections import Counter\n",
        "from os import listdir, remove, chdir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXkaw22gKdL8"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')\n",
        "chdir(\"./drive/MyDrive/Hishuvit4/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHWgV2fa6HEK"
      },
      "source": [
        "# Part A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-02T13:16:22.091993Z",
          "iopub.status.busy": "2022-10-02T13:16:22.091499Z",
          "iopub.status.idle": "2022-10-02T13:16:22.107879Z",
          "shell.execute_reply": "2022-10-02T13:16:22.106379Z",
          "shell.execute_reply.started": "2022-10-02T13:16:22.091945Z"
        },
        "id": "ggR-vAl96HEL",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class CBFS:\n",
        "  def __init__(self, k):\n",
        "    # Only one hyper parameter - k - the number of features we want to choose\n",
        "    self.k = k\n",
        "\n",
        "  def Ic(self, ec, u):\n",
        "    # The Ic function\n",
        "    res = np.mean(ec.cdf(u))\n",
        "    return np.abs(np.log2(res) * res if res != 0. else 0.)\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    # The algorithm described in the paper \"Stable feature selection using copula based mutual information\"\n",
        "    n, col = X.shape\n",
        "    u = np.random.uniform(size=(n, 2))\n",
        "    temp = np.c_[y, X]\n",
        "    mimc1 = np.array([self.Ic(EmpiricalCopula(pseudo_obs(temp[:, [0, j + 1]])), u) for j in range(col)]) # Mutual information of all features with y\n",
        "    output = [np.argmax(mimc1)]\n",
        "    for m in range(1, self.k):\n",
        "      u = np.random.uniform(size=(n, m + 1))\n",
        "      temp = np.c_[X.iloc[:, output] if type(X) == pd.DataFrame else X[:, output], X]\n",
        "      red = np.array([self.Ic(EmpiricalCopula(pseudo_obs(temp[:, list(range(m)) + [m + j]])), u) if j not in output else np.NINF for j in range(col)]) # The mutual information of each feature with the currently selected features\n",
        "      result = mimc1 - red # Subtract the mutual information of each feature with the currently selected features from the mutual information of each feature with y\n",
        "      output.append(np.argmin(result)) # Add the best result to the output\n",
        "    self.mask_ = np.zeros(col, dtype=np.int32)\n",
        "    self.mask_[output] = 1\n",
        "    self.scores_ = self.mask_\n",
        "    return self\n",
        "\n",
        "  def transform(self, X):\n",
        "    if (self.mask_ is None):\n",
        "        raise Exception(\"Can't transform data without fitting first\")\n",
        "    if (type(X) == pd.DataFrame):\n",
        "      return X[X.columns[self.mask_ == 1]]\n",
        "    return X[self.mask_ == 1]\n",
        "\n",
        "  def fit_transform(self, X, y):\n",
        "    self.fit(X, y)\n",
        "    return self.transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-02T13:16:22.112365Z",
          "iopub.status.busy": "2022-10-02T13:16:22.111445Z",
          "iopub.status.idle": "2022-10-02T13:16:22.136405Z",
          "shell.execute_reply": "2022-10-02T13:16:22.135142Z",
          "shell.execute_reply.started": "2022-10-02T13:16:22.112312Z"
        },
        "id": "Y2s-Xp_36HEM",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class XSpace:\n",
        "  def __init__(self, X, c, k):\n",
        "    self.X = X\n",
        "    self.c = c\n",
        "    self.k = k\n",
        "    self.cache_neighbors = dict()\n",
        "  \n",
        "  def is_nearest_neighbors(self, i, j, cFlag=None):\n",
        "    if (i in self.cache_neighbors):\n",
        "      nearest_neighbors_ids = self.cache_neighbors[i]\n",
        "    else:\n",
        "      X_i = np.delete(self.X, i, axis=0)\n",
        "      nearest_neighbors_ids = np.linalg.norm(self.X[i] - X_i, axis=1).argsort()[:self.k]\n",
        "      self.cache_neighbors[i] = nearest_neighbors_ids\n",
        "    if(cFlag == None):\n",
        "      return j in nearest_neighbors_ids\n",
        "    elif(cFlag == \"w\"):\n",
        "      return j in nearest_neighbors_ids and self.c[i] == self.c[j]\n",
        "    else:\n",
        "      return j in nearest_neighbors_ids and self.c[i] != self.c[j]\n",
        "\n",
        "\n",
        "class LSLSFS:\n",
        "  def __init__(self, k):\n",
        "    # Only one hyper parameter - k - the number of features we want to choose\n",
        "    # Note: if we had enough computation power, alpha could've been a hyper parameter as well, but sadly we do not have access to good computation power\n",
        "    self.k = k\n",
        "    self.alpha = 0.5\n",
        "    \n",
        "  def compute_W(self, xSpace, X, m, cFlag=None):\n",
        "    return np.array([[np.abs(X[i].T @ X[j]) / (np.linalg.norm(X[i]) * np.linalg.norm(X[j])) if xSpace.is_nearest_neighbors(i, j, cFlag) or xSpace.is_nearest_neighbors(j, i, cFlag) else 0 for j in range(m)] for i in range(m)])\n",
        "\n",
        "  def compute_D(self, W, m):\n",
        "    return np.diag(np.array([sum(W[:, i]) for i in range(m)]))\n",
        "\n",
        "  def compute_L(self, W, D):\n",
        "    return D - W\n",
        "\n",
        "  def compute_fr(self, X, D, r, m):\n",
        "    fr = X[:, r]\n",
        "    ones = np.ones(m)\n",
        "    numerator = fr @ D @ ones\n",
        "    denominator = ones @ D @ ones\n",
        "    return fr.T - ((numerator/denominator) * ones)\n",
        "\n",
        "  def compute_LSLSr(self, fr, Lw, Lb, D):\n",
        "    aLw = self.alpha * Lw\n",
        "    aLb = (1 - self.alpha) * Lb\n",
        "    numerator = fr.T @ (aLw - aLb) @ fr\n",
        "    denominator = fr.T @ D @ fr\n",
        "    return numerator / denominator\n",
        "\n",
        "  def fit(self, X, y=None):\n",
        "    XT = X.to_numpy() if type(X) == pd.DataFrame else X\n",
        "    m, n = X.shape\n",
        "    xSpace = XSpace(XT, y, self.k)\n",
        "    W = self.compute_W(xSpace, XT, m)\n",
        "    D = self.compute_D(W, m)\n",
        "\n",
        "    Ww = self.compute_W(xSpace, XT, m, cFlag=\"w\")\n",
        "    Dw = self.compute_D(Ww, m)\n",
        "    Lw = self.compute_L(Ww, Dw)\n",
        "\n",
        "    Wb = self.compute_W(xSpace, XT, m, cFlag=\"b\")\n",
        "    Db = self.compute_D(Wb, m)\n",
        "    Lb = self.compute_L(Wb, Db)\n",
        "\n",
        "    scores = np.array([self.compute_LSLSr(self.compute_fr(XT, D, r, m), Lw, Lb, D) for r in range(n)])\n",
        "\n",
        "    self.scores_ = scores\n",
        "    self.mask_ = np.zeros(n, dtype=np.int32)\n",
        "    self.mask_[np.argsort(self.scores_)[::-1][:self.k]] = 1\n",
        "    return self\n",
        "    \n",
        "  def transform(self, X):\n",
        "    if (self.mask_ is None):\n",
        "        raise Exception(\"Can't transform data without fitting first\")\n",
        "    if (type(X) == pd.DataFrame):\n",
        "      return X[X.columns[self.mask_ == 1]]\n",
        "    return X[self.mask_ == 1]\n",
        "\n",
        "  def fit_transform(self, X, y):\n",
        "    self.fit(X, y)\n",
        "    return self.transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-02T13:16:22.138511Z",
          "iopub.status.busy": "2022-10-02T13:16:22.138016Z",
          "iopub.status.idle": "2022-10-02T13:16:26.322811Z",
          "shell.execute_reply": "2022-10-02T13:16:26.321667Z",
          "shell.execute_reply.started": "2022-10-02T13:16:22.138468Z"
        },
        "id": "sVSMAV_U6HEN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(f\"Data/SPECTF.train\", header=None)\n",
        "X_train = train_df.iloc[:, 1:]\n",
        "y_train = train_df.iloc[:, 0]\n",
        "\n",
        "test_df = pd.read_csv(f\"Data/SPECTF.test\", header=None)\n",
        "X_test = test_df.iloc[:, 1:]\n",
        "y_test = test_df.iloc[:, 0]\n",
        "\n",
        "base_model = RandomForestClassifier()\n",
        "base_model.fit(X_train, y_train)\n",
        "print(f\"Model accuracy without feature selection: {accuracy_score(base_model.predict(X_test), y_test)}\")\n",
        "for k in range(5, 15, 3):\n",
        "  model = make_pipeline(CBFS(k), RandomForestClassifier())\n",
        "  model.fit(X_train, y_train)\n",
        "  print(f\"Model accuracy with CBFS with k={k}: {accuracy_score(model.predict(X_test), y_test)}\")\n",
        "\n",
        "for k in range(5, 15, 3):\n",
        "  model = make_pipeline(LSLSFS(k), RandomForestClassifier())\n",
        "  model.fit(X_train, y_train)\n",
        "  print(f\"Model accuracy with LSLSFS with k={k}: {accuracy_score(model.predict(X_test), y_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keJpWUbG6HEN"
      },
      "source": [
        "# Part C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-02T13:16:26.327232Z",
          "iopub.status.busy": "2022-10-02T13:16:26.326721Z",
          "iopub.status.idle": "2022-10-02T13:16:26.342434Z",
          "shell.execute_reply": "2022-10-02T13:16:26.341096Z",
          "shell.execute_reply.started": "2022-10-02T13:16:26.327196Z"
        },
        "id": "lah8tjKS6HEO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class New_CBFS:\n",
        "  def __init__(self, k):\n",
        "    # Only one hyper parameter - k - the number of features we want to choose\n",
        "    # Note: if we had enough computation power, q could've been a hyper parameter as well, but sadly we do not have access to good computation power\n",
        "    self.k = k\n",
        "    self.q = 0.3\n",
        "\n",
        "  def Ic(self, ec, u):\n",
        "    # Tsallis Entropy based Ic calculation\n",
        "    return np.mean(1 - (ec.cdf(u) ** self.q)) / (self.q - 1)\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    n, col = X.shape\n",
        "    u = np.random.uniform(size=(n, 2))\n",
        "    temp = np.c_[y, X]\n",
        "    mimc1 = np.array([self.Ic(EmpiricalCopula(pseudo_obs(temp[:, [0, j + 1]])), u) for j in range(col)]) # Mutual information of all features with y\n",
        "    output = [np.argmax(mimc1)]\n",
        "    for m in range(1, self.k):\n",
        "      u = np.random.uniform(size=(n, m + 1))\n",
        "      temp = np.c_[X.iloc[:, output] if type(X) == pd.DataFrame else X[:, output], X]\n",
        "      red = np.array([self.Ic(EmpiricalCopula(pseudo_obs(temp[:, list(range(m)) + [m + j]])), u) if j not in output else np.NINF for j in range(col)]) # The mutual information of each feature with the currently selected features\n",
        "      result = mimc1 - red # Subtract the mutual information of each feature with the currently selected features from the mutual information of each feature with y\n",
        "      output.append(np.argmin(result)) # Add the best result to the output\n",
        "    self.mask_ = np.zeros(col, dtype=np.int32)\n",
        "    self.mask_[output] = 1\n",
        "    self.scores_ = self.mask_\n",
        "    return self\n",
        "\n",
        "  def transform(self, X):\n",
        "    if (self.mask_ is None):\n",
        "        raise Exception(\"Can't transform data without fitting first\")\n",
        "    if (type(X) == pd.DataFrame):\n",
        "      return X[X.columns[self.mask_ == 1]]\n",
        "    return X[self.mask_ == 1]\n",
        "\n",
        "  def fit_transform(self, X, y):\n",
        "    self.fit(X, y)\n",
        "    return self.transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-02T13:16:26.344527Z",
          "iopub.status.busy": "2022-10-02T13:16:26.344061Z",
          "iopub.status.idle": "2022-10-02T13:16:28.942334Z",
          "shell.execute_reply": "2022-10-02T13:16:28.941108Z",
          "shell.execute_reply.started": "2022-10-02T13:16:26.344481Z"
        },
        "id": "K4bLlqFN6HEO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(f\"Data/SPECTF.train\", header=None)\n",
        "X_train = train_df.iloc[:, 1:]\n",
        "y_train = train_df.iloc[:, 0]\n",
        "\n",
        "test_df = pd.read_csv(f\"Data/SPECTF.test\", header=None)\n",
        "X_test = test_df.iloc[:, 1:]\n",
        "y_test = test_df.iloc[:, 0]\n",
        "\n",
        "base_model = RandomForestClassifier()\n",
        "base_model.fit(X_train, y_train)\n",
        "print(f\"Model accuracy without feature selection: {accuracy_score(base_model.predict(X_test), y_test)}\")\n",
        "for k in range(5, 15, 3):\n",
        "  model = make_pipeline(New_CBFS(k), RandomForestClassifier())\n",
        "  model.fit(X_train, y_train)\n",
        "  print(f\"Model accuracy with New_CBFS with k={k}: {accuracy_score(model.predict(X_test), y_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBKDg7916HEP"
      },
      "source": [
        "# Part B and C experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-02T13:16:28.944657Z",
          "iopub.status.busy": "2022-10-02T13:16:28.943699Z",
          "iopub.status.idle": "2022-10-02T13:16:28.954292Z",
          "shell.execute_reply": "2022-10-02T13:16:28.953134Z",
          "shell.execute_reply.started": "2022-10-02T13:16:28.944621Z"
        },
        "id": "BkePkShT6HEP",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class ReliefF:\n",
        "  def __init__(self, k):\n",
        "    self.k = k\n",
        "    \n",
        "  def fit(self, X, y):\n",
        "    n, col = X.shape\n",
        "    self.n_features_in_ = col\n",
        "    if type(X) == pd.DataFrame:\n",
        "      X = X.to_numpy()\n",
        "    if type(y) == pd.DataFrame:\n",
        "      y = y.to_numpy()\n",
        "    self.scores_ = reliefF(X, y, mode=\"raw\", k=self.k)\n",
        "    self.mask_ = np.zeros(col, dtype=np.int32)\n",
        "    self.mask_[np.argsort(self.scores_, 0)[::-1][:self.k]] = 1\n",
        "    return self\n",
        "\n",
        "  def transform(self, X, y=None):\n",
        "    if (self.mask_ is None):\n",
        "      raise Exception(\"Can't transform data without fitting first\")\n",
        "    if (type(X) == pd.DataFrame):\n",
        "      return X[X.columns[self.mask_ == 1]]\n",
        "    return X[self.mask_ == 1]\n",
        "\n",
        "  def fit_transform(self, X, y):\n",
        "    self.fit(X, y)\n",
        "    return self.transform(X)\n",
        "\n",
        "\n",
        "class MRMR:\n",
        "  def __init__(self, k):\n",
        "    self.k = k\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    n, col = X.shape\n",
        "    self.n_features_in_ = col\n",
        "    if type(X) == pd.DataFrame:\n",
        "      X = X.to_numpy()\n",
        "    if type(y) == pd.DataFrame:\n",
        "      y = y.to_numpy()\n",
        "    self.fs = mrmr(X, y, mode='index', n_selected_features=self.k)\n",
        "    self.mask_ = np.zeros(col, dtype=np.int32)\n",
        "    self.mask_[self.fs] = 1\n",
        "    self.scores_ = self.mask_\n",
        "    return self\n",
        "\n",
        "  def transform(self, X, y=None):\n",
        "    if (self.mask_ is None):\n",
        "      raise Exception(\"Can't transform data without fitting first\")\n",
        "    if (type(X) == pd.DataFrame):\n",
        "      return X[X.columns[self.mask_ == 1]]\n",
        "    return X[self.mask_ == 1]\n",
        "\n",
        "  def fit_transform(self, X, y):\n",
        "    self.fit(X, y)\n",
        "    return self.transform(X)\n",
        "\n",
        "\n",
        "class CustomFDR:\n",
        "  def __init__(self, k):\n",
        "    pass\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    n, col = X.shape\n",
        "    self.n_features_in_ = col\n",
        "    if type(X) == pd.DataFrame:\n",
        "      X = X.to_numpy()\n",
        "    if type(y) == pd.DataFrame:\n",
        "      y = y.to_numpy()\n",
        "    self.fs = SelectFdr(score_func=f_classif, alpha=0.1)\n",
        "    self.fs.fit(X, y)\n",
        "    self.scores_ = self.fs.scores_\n",
        "    self.mask_ = np.zeros(col, dtype=np.int32)\n",
        "    temp = self.fs.get_support()\n",
        "    if True in temp:\n",
        "      self.mask_[temp] = 1\n",
        "    else:\n",
        "      self.mask_[np.argmax(self.scores_)] = 1\n",
        "    return self\n",
        "\n",
        "  def transform(self, X, y=None):\n",
        "    if (self.mask_ is None):\n",
        "      raise Exception(\"Can't transform data without fitting first\")\n",
        "    if (type(X) == pd.DataFrame):\n",
        "      return X[X.columns[self.mask_ == 1]]\n",
        "    return X[self.mask_ == 1]\n",
        "\n",
        "  def fit_transform(self, X, y):\n",
        "    self.fit(X, y)\n",
        "    return self.transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-02T13:16:28.990073Z",
          "iopub.status.busy": "2022-10-02T13:16:28.989657Z",
          "iopub.status.idle": "2022-10-02T13:16:29.002303Z",
          "shell.execute_reply": "2022-10-02T13:16:29.001194Z",
          "shell.execute_reply.started": "2022-10-02T13:16:28.990038Z"
        },
        "id": "OqaAR6XR6HEQ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "MEASURE_TYPES = [\"ACC\", \"PR-AUC\", \"AUC\", \"MCC\"]\n",
        "\n",
        "header = ['Dataset Name', 'Number of samples', 'Original number of features', \n",
        "                  'Filtering Algorithm', 'Learning Algorithm', 'Number of features selected (K)', \n",
        "                  'CV Method', 'Fold', 'Measure Type', 'Measure Value', 'List of Selected Features Names', \n",
        "                  'Selected Features Scores', 'Training time (whole pipeline)', 'Testing time']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-02T13:16:29.004825Z",
          "iopub.status.busy": "2022-10-02T13:16:29.004099Z",
          "iopub.status.idle": "2022-10-02T13:16:29.048666Z",
          "shell.execute_reply": "2022-10-02T13:16:29.047677Z",
          "shell.execute_reply.started": "2022-10-02T13:16:29.004782Z"
        },
        "id": "mP1FUHgZ6HER",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "TRUE_CLASS_LABEL_INDEX = 1\n",
        "\n",
        "def multiclass_to_binary(y, c):\n",
        "  return (y == c).astype(int)\n",
        "\n",
        "def write_to_results(RESULTS_FILENAME, DATASET_NAME, NUMBER_OF_SAMPLES,\n",
        "                     ORIGINAL_NUMBER_OF_FEATURES, FILTERING_ALGORITHM, \n",
        "                     LEARNING_ALGORITHM, NUMBER_OF_FEATURES_SELECTED, \n",
        "                     CV_METHOD, FOLD, \n",
        "                     MEASURE_VALUES, SELECTED_FEATURES_NAMES, \n",
        "                     SELECTED_FEATURES_SCORES, PIPELINE_TIME, TEST_TIME):\n",
        "  if not exists(RESULTS_FILENAME):\n",
        "    with open(RESULTS_FILENAME, 'w+', encoding='UTF8') as f:\n",
        "      writer = csv.writer(f)\n",
        "      writer.writerow(header)\n",
        "  \n",
        "  rows = [[DATASET_NAME, NUMBER_OF_SAMPLES, ORIGINAL_NUMBER_OF_FEATURES, \n",
        "         FILTERING_ALGORITHM, LEARNING_ALGORITHM, NUMBER_OF_FEATURES_SELECTED,\n",
        "         CV_METHOD, FOLD, MEASURE_TYPE, MEASURE_VALUE, SELECTED_FEATURES_NAMES,\n",
        "         SELECTED_FEATURES_SCORES, PIPELINE_TIME, TEST_TIME] for MEASURE_TYPE, MEASURE_VALUE in zip(MEASURE_TYPES, MEASURE_VALUES)]\n",
        "  with open(RESULTS_FILENAME, 'a', encoding='UTF8', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(rows)\n",
        "\n",
        "class Switch:\n",
        "  def __init__(self, datasetname=None, preprocessing=None, fs=None, estimator=None, k=None, results_file=None):\n",
        "      self.preprocessing = preprocessing\n",
        "      self.fs = fs\n",
        "      self.estimator = estimator\n",
        "      self.datasetname = datasetname\n",
        "      self.k = k\n",
        "      self.results_file = results_file\n",
        "\n",
        "  def get_params(self, deep=True):\n",
        "      return {'preprocessing': self.preprocessing,\n",
        "              'fs': self.fs,\n",
        "              'estimator': self.estimator,\n",
        "              'datasetname': self.datasetname,\n",
        "              'k': self.k,\n",
        "              'results_file': self.results_file}\n",
        "\n",
        "  def set_params(self, **params):\n",
        "    if not params:\n",
        "      return self\n",
        "\n",
        "    for key, value in params.items():\n",
        "      if hasattr(self, key):\n",
        "        setattr(self, key, value)\n",
        "      else:\n",
        "        self.kwargs[key] = value\n",
        "    return self\n",
        "\n",
        "  def __getstate__(self):\n",
        "      state = self.__dict__.copy()\n",
        "      return state\n",
        "\n",
        "  def __setstate__(self, state):\n",
        "      self.__dict__.update(state)\n",
        "\n",
        "  def get_features(self, X_train):\n",
        "    if hasattr(self.fs, 'support_'):\n",
        "      feature_names = \", \".join(str(n) for n in (X_train[X_train.columns[self.fs.support_ == 1]] if type(X_train) == pd.DataFrame else X_train[self.fs.support_ == 1]))\n",
        "      if hasattr(self.fs, 'scores_'):\n",
        "        feature_scores = \", \".join(str(n) for n in self.fs.scores_[self.fs.support_ == 1])\n",
        "      elif hasattr(self.fs, 'ranking_'):\n",
        "        feature_scores = \", \".join(str(n) for n in self.fs.ranking_[self.fs.support_ == 1])\n",
        "      else:\n",
        "        raise Exception(f\"No scores_ and no ranking_: {self.FILTERING_ALGORITHM}\")\n",
        "\n",
        "    elif hasattr(self.fs, 'mask_'):\n",
        "      feature_names = \", \".join(str(n) for n in (X_train[X_train.columns[self.fs.mask_ == 1]] if type(X_train) == pd.DataFrame else X_train[self.fs.mask_ == 1]))\n",
        "      if hasattr(self.fs, 'scores_'):\n",
        "        feature_scores = \", \".join(str(n) for n in self.fs.scores_[self.fs.mask_ == 1])\n",
        "      elif hasattr(self.fs, 'ranking_'):\n",
        "        feature_scores = \", \".join(str(n) for n in self.fs.ranking_[self.fs.mask_ == 1])\n",
        "      else:\n",
        "        raise Exception(f\"No scores_ and no ranking_: {self.FILTERING_ALGORITHM}\")\n",
        "\n",
        "    else:\n",
        "      raise Exception(f\"No mask_ and no support_: {self.FILTERTING_ALGORITHM}\")\n",
        "    return feature_names, feature_scores\n",
        "\n",
        "  def evaluate(self, X_train, X_test, y_train, y_test):\n",
        "    _, y_train = np.unique(y_train, return_inverse=True)\n",
        "    _, y_test = np.unique(y_test, return_inverse=True)\n",
        "    PIPELINE_TIME = time()\n",
        "    self.current_model.fit(X_train, y_train)\n",
        "    PIPELINE_TIME = time() - PIPELINE_TIME\n",
        "    \n",
        "    testing_start_time = time()\n",
        "    y_pred = self.current_model.predict(X_test)\n",
        "    y_pred_proba = self.current_model.predict_proba(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    temp = np.unique(y_test)\n",
        "\n",
        "    if len(temp) == 1: # Only one class in the test set\n",
        "      rocauc = acc\n",
        "      prauc = average_precision_score(y_test, y_pred_proba[:, 0])\n",
        "    elif len(temp) == 2: # Binary classification in the test set\n",
        "      rocauc = roc_auc_score(y_test, y_pred_proba[:, TRUE_CLASS_LABEL_INDEX])\n",
        "      prauc = average_precision_score(y_test, y_pred_proba[:, TRUE_CLASS_LABEL_INDEX])\n",
        "    else: # Multi-class\n",
        "      rocauc = roc_auc_score(y_test, y_pred_proba, multi_class='ovo', labels=list(set(np.unique(y_train)).union(set(np.unique(y_test)))))\n",
        "      prauc = sum(average_precision_score(multiclass_to_binary(y_test, c), y_pred_proba[:, c]) for c in temp) / len(temp)\n",
        "    mcc = matthews_corrcoef(y_test, y_pred)\n",
        "    TESTING_TIME = time() - testing_start_time\n",
        "    feature_names, feature_scores = self.get_features(X_train)\n",
        "    return str(PIPELINE_TIME), str(TESTING_TIME), feature_names, feature_scores, [str(acc), str(prauc), str(rocauc), str(mcc)]\n",
        "\n",
        "  def fit(self, X, y=None):\n",
        "    NUMBER_OF_SAMPLES, ORIGINAL_NUMBER_OF_FEATURES = X.shape\n",
        "    FILTERING_ALGORITHM = self.fs[0]\n",
        "    LEARNING_ALGORITHM = self.estimator[0]\n",
        "    self.fs = self.fs[1](self.k)\n",
        "    self.estimator = self.estimator[1]()\n",
        "    DATASET_NAME = self.datasetname\n",
        "    NUMBER_OF_FEATURES_SELECTED = self.k\n",
        "    self.current_model = make_pipeline(self.preprocessing, self.fs, self.estimator)\n",
        "    if NUMBER_OF_SAMPLES < 50:\n",
        "      cv, CV_METHOD = LeavePOut(2), \"Leave-pair-out\"\n",
        "    elif 50 < NUMBER_OF_SAMPLES < 100:\n",
        "      cv, CV_METHOD = LeaveOneOut(), \"Leave-one-out\"\n",
        "    elif 100 < NUMBER_OF_SAMPLES < 1000:\n",
        "      cv, CV_METHOD = StratifiedKFold(n_splits=10), \"10-Folds cv\"\n",
        "    else:\n",
        "      cv, CV_METHOD = StratifiedKFold(n_splits=5), \"5-Folds cv\"\n",
        "\n",
        "    for fold_num, (train_index, test_index) in enumerate(cv.split(X, y)):\n",
        "      if type(X) == pd.DataFrame:\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "      else:\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "      y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "      PIPELINE_TIME, MODEL_TRAINING_TIME, TEST_TIME, SELECTED_FEATURES_NAMES, SELECTED_FEATURES_SCORES, MEASURE_VALUES = self.evaluate(X_train, X_test, y_train, y_test)\n",
        "\n",
        "      FOLD = str(fold_num + 1)\n",
        "      write_to_results(self.results_file, DATASET_NAME, NUMBER_OF_SAMPLES, ORIGINAL_NUMBER_OF_FEATURES, FILTERING_ALGORITHM, LEARNING_ALGORITHM, NUMBER_OF_FEATURES_SELECTED, CV_METHOD, FOLD, MEASURE_VALUES, SELECTED_FEATURES_NAMES, SELECTED_FEATURES_SCORES, PIPELINE_TIME, TEST_TIME)\n",
        "    return self\n",
        "\n",
        "  def predict(self, X, y=None):\n",
        "    return self.current_model.predict(X)\n",
        "\n",
        "  def predict_proba(self, X):\n",
        "    return self.current_model.predict_proba(X)\n",
        "\n",
        "  def score(self, X, y):\n",
        "    return self.current_model.score(X, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-02T13:16:29.051450Z",
          "iopub.status.busy": "2022-10-02T13:16:29.050057Z",
          "iopub.status.idle": "2022-10-02T13:16:29.067198Z",
          "shell.execute_reply": "2022-10-02T13:16:29.066006Z",
          "shell.execute_reply.started": "2022-10-02T13:16:29.051407Z"
        },
        "id": "ac8O8s-86HES",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "FS_NAMES = ['RFE_USING_SVM',\n",
        "            'F_CLASSIF_FDR10%',\n",
        "            'MRMR',\n",
        "            'ReliefF',\n",
        "            'New_CBFS',\n",
        "            'CBFS',\n",
        "            'LSLSFS']\n",
        "\n",
        "FS_METHODS = [lambda k: RFE(SVR(kernel=\"linear\"), n_features_to_select=k),\n",
        "            CustomFDR,\n",
        "            MRMR,\n",
        "            ReliefF,\n",
        "            New_CBFS,\n",
        "            CBFS,\n",
        "            LSLSFS]\n",
        "\n",
        "K_VALUES = [1, 2, 3, 4, 5, 10, 15, 20, 25, 30, 50, 100]\n",
        "\n",
        "CLFS_NAMES = ['KNN',\n",
        "              'Gaussian Naive Bayes',\n",
        "              'SVM',\n",
        "              'Logistic Regression',\n",
        "              'Random Forest']\n",
        "\n",
        "CLFS = [KNeighborsClassifier,\n",
        "        GaussianNB,\n",
        "        lambda: SVC(kernel='linear', gamma='auto', probability=True),\n",
        "        LogisticRegression,\n",
        "        RandomForestClassifier]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-02T13:16:29.069318Z",
          "iopub.status.busy": "2022-10-02T13:16:29.068369Z",
          "iopub.status.idle": "2022-10-02T13:16:29.085464Z",
          "shell.execute_reply": "2022-10-02T13:16:29.084457Z",
          "shell.execute_reply.started": "2022-10-02T13:16:29.069279Z"
        },
        "id": "XEDBiXFA6HES",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def full_comparison_part_b(X, y, dataset_name, results_filename, preprocess_filename, preprocessing=None):\n",
        "  curr_preprocessing = make_pipeline(SimpleImputer(), VarianceThreshold(), PowerTransformer())\n",
        "  REDUCE_FEATURES = X.shape[1] > 1000\n",
        "  if REDUCE_FEATURES:\n",
        "    curr_preprocessing.steps.append(['initial_feature_reducer', SelectKBest(k=1000)])\n",
        "  if preprocessing is not None:\n",
        "    curr_preprocessing.steps.append(['custom_preprocessing', preprocessing])\n",
        "  X_new = curr_preprocessing.fit_transform(X, y)\n",
        "  new_cols = X.columns[curr_preprocessing['initial_feature_reducer'].get_support()] if REDUCE_FEATURES else X.columns\n",
        "  X = pd.DataFrame(X_new, columns=new_cols, index=X.index)\n",
        "  X.to_csv(preprocess_filename)\n",
        "  parameters = {'datasetname': [dataset_name],\n",
        "                'fs': list(zip(FS_NAMES, FS_METHODS)),\n",
        "                'estimator': list(zip(CLFS_NAMES, CLFS)),\n",
        "                'k': K_VALUES,\n",
        "                'results_file': [results_filename]}\n",
        "\n",
        "  gscv = GridSearchCV(Switch(), parameters, n_jobs=-1)\n",
        "  gscv.fit(X, y)\n",
        "\n",
        "def get_x_y(ds_group, ds_name):\n",
        "  if ds_group == 'mAMLData':\n",
        "    df = pd.read_csv(f\"Data/{ds_group}/{ds_name}/{ds_name}.csv\", index_col = 0)\n",
        "    X = df\n",
        "    samples_names = X.index\n",
        "    df_labels = pd.read_csv(f\"Data/{ds_group}/{ds_name}/{ds_name}.mf.csv\")\n",
        "    y = np.array([df_labels.loc[df_labels['#SampleID'] == samples_names[index]][\"label\"].iloc[0] for index in range(X.shape[0])])\n",
        "  elif ds_group == 'bioconductor':\n",
        "    df = pd.read_csv(f\"Data/{ds_group}/{ds_name}.csv\", index_col=0).T\n",
        "    X = df.iloc[:, 1:]\n",
        "    y = df.iloc[:, 0].to_numpy(dtype=np.int32)\n",
        "  elif ds_group == 'datamicroarray':\n",
        "    X = pd.read_csv(f\"Data/{ds_group}/{ds_name}_inputs.csv\")\n",
        "    y = pd.read_csv(f\"Data/{ds_group}/{ds_name}_outputs.csv\").to_numpy(dtype=np.int32).ravel()\n",
        "  elif ds_group == 'microbiomicData':\n",
        "    df = pd.read_csv(f\"Data/{ds_group}/{ds_name}.csv\")\n",
        "    X = df.iloc[:, :-1]\n",
        "    y = df.iloc[:, -1].values\n",
        "  return X, y\n",
        "\n",
        "def run_part_b(ds_group, ds_name):\n",
        "  X, y = get_x_y(ds_group, ds_name)\n",
        "  results_filename = f\"Results/{ds_group}/{ds_name}/{ds_name}_res.csv\"\n",
        "  preprocess_filename = f\"Results/{ds_group}/{ds_name}/{ds_name}_PROCESSED.csv\"\n",
        "  if not exists(results_filename):\n",
        "    with open(results_filename, 'w+', encoding='UTF8') as f:\n",
        "      writer = csv.writer(f)\n",
        "      writer.writerow(header)\n",
        "\n",
        "  full_comparison_part_b(X, y, ds_name, results_filename, preprocess_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vihihHw2Ml0d"
      },
      "outputs": [],
      "source": [
        "for ds_group in listdir('Data'):\n",
        "  if isdir(f\"Data/{ds_group}\"): # We don't want SPECTF.test, SPECTF.train\n",
        "    for ds_name in listdir(f\"Data/{ds_group}\"):\n",
        "      run_part_b(ds_group, ds_name[:-4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5bxelX7Jog5"
      },
      "source": [
        "# Part D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qPGmAgt3Jur5"
      },
      "outputs": [],
      "source": [
        "header_part_d = ['Dataset Name', 'Number of samples', 'Original number of features', \n",
        "                  'Filtering Algorithm', 'Learning Algorithm', 'Number of features selected (K)', \n",
        "                  'CV Method', 'Fold', 'Measure Type', 'Measure Value', 'Training time (whole pipeline)', 'Testing time']\n",
        "\n",
        "FS = dict(zip(FS_NAMES, FS_METHODS))\n",
        "\n",
        "CLFS_METHODS = dict(zip(CLFS_NAMES, CLFS))\n",
        "\n",
        "def write_to_results_part_d(RESULTS_FILENAME, DATASET_NAME, NUMBER_OF_SAMPLES,\n",
        "                     ORIGINAL_NUMBER_OF_FEATURES, FILTERING_ALGORITHM, \n",
        "                     LEARNING_ALGORITHM, NUMBER_OF_FEATURES_SELECTED, \n",
        "                     CV_METHOD, FOLD,\n",
        "                     MEASURE_VALUES, PIPELINE_TIME, TEST_TIME):\n",
        "  if not exists(RESULTS_FILENAME):\n",
        "    with open(RESULTS_FILENAME, 'w+', encoding='UTF8') as f:\n",
        "      writer = csv.writer(f)\n",
        "      writer.writerow(header_part_d)\n",
        "\n",
        "  rows = [[DATASET_NAME, NUMBER_OF_SAMPLES, ORIGINAL_NUMBER_OF_FEATURES, \n",
        "         FILTERING_ALGORITHM, LEARNING_ALGORITHM, NUMBER_OF_FEATURES_SELECTED,\n",
        "         CV_METHOD, FOLD, MEASURE_TYPE, MEASURE_VALUE, PIPELINE_TIME, TEST_TIME] for MEASURE_TYPE, MEASURE_VALUE in zip(MEASURE_TYPES, MEASURE_VALUES)]\n",
        "  with open(RESULTS_FILENAME, 'a', encoding='UTF8', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(rows)\n",
        "\n",
        "def run_part_d(X, y, dataset_name, res_file_name):\n",
        "    RESULTS_FILENAME = f\"Results_PartD/{dataset_name}_res_aug.csv\"\n",
        "    print(f\"Reading file {res_file_name}...\")\n",
        "    res_df = pd.read_csv(res_file_name, header=0)\n",
        "    best_auc_row_idx = res_df[res_df[\"Measure Type\"] == 'AUC'][\"Measure Value\"].idxmax()\n",
        "    best_auc_row = res_df.iloc[best_auc_row_idx]\n",
        "    winning_fs = best_auc_row[\"Filtering Algorithm\"]\n",
        "    winning_k = best_auc_row[\"Number of features selected (K)\"]\n",
        "    winning_clf = best_auc_row[\"Learning Algorithm\"]\n",
        "    fs_algo = FS[winning_fs](winning_k)\n",
        "    # Part D - A starts here!\n",
        "    with open(\"PartD_ChosenConfigurations.txt\", \"a+\") as f:\n",
        "      f.write(f\"For dataset {dataset_name}, the best configuration is feature selection algorithm {winning_fs}, number of features (k) {winning_k} and classifier {winning_clf}\\n\")\n",
        "      print(f\"For dataset {dataset_name}, the best configuration is feature selection algorithm {winning_fs}, number of features (k) {winning_k} and classifier {winning_clf}\")\n",
        "\n",
        "    X_new = fs_algo.fit_transform(X, y)\n",
        "    X = pd.DataFrame(X_new, index=X.index)\n",
        "    part_d(X, y, winning_fs, fs_algo, winning_clf, dataset_name, winning_k, RESULTS_FILENAME)\n",
        "   \n",
        "    \n",
        "def evaluate_part_d(X_train, X_test, y_train, y_test, model):\n",
        "    _, y_train = np.unique(y_train, return_inverse=True)\n",
        "    _, y_test = np.unique(y_test, return_inverse=True)\n",
        "\n",
        "    TRAINING_TIME = time()\n",
        "    model.fit(X_train, y_train)\n",
        "    TRAINING_TIME = time() - TRAINING_TIME\n",
        "    \n",
        "    TESTING_TIME = time()\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    temp = np.unique(y_test)\n",
        "\n",
        "    if len(temp) == 1: # Only one class in the test set\n",
        "      rocauc = acc\n",
        "      prauc = average_precision_score(y_test, y_pred_proba[:, 0])\n",
        "    elif len(temp) == 2: # Binary classification in the test set\n",
        "      rocauc = roc_auc_score(y_test, y_pred_proba[:, TRUE_CLASS_LABEL_INDEX])\n",
        "      prauc = average_precision_score(y_test, y_pred_proba[:, TRUE_CLASS_LABEL_INDEX])\n",
        "    else: # Multi-class\n",
        "      rocauc = roc_auc_score(y_test, y_pred_proba, multi_class='ovo', labels=list(set(np.unique(y_train)).union(set(np.unique(y_test)))))\n",
        "      prauc = sum(average_precision_score(multiclass_to_binary(y_test, c), y_pred_proba[:, c]) for c in temp) / len(temp)\n",
        "    mcc = matthews_corrcoef(y_test, y_pred)\n",
        "    TESTING_TIME = time() - TESTING_TIME\n",
        "    \n",
        "    return str(TRAINING_TIME), str(TESTING_TIME), [str(acc), str(prauc), str(rocauc), str(mcc)]\n",
        "    \n",
        "def part_d(X, y, FILTERING_ALGORITHM, fs, LEARNING_ALGORITHM, DATASET_NAME, k, results_file):\n",
        "    NUMBER_OF_SAMPLES, ORIGINAL_NUMBER_OF_FEATURES = X.shape\n",
        "    NUMBER_OF_FEATURES_SELECTED = k\n",
        "    if NUMBER_OF_SAMPLES < 50:\n",
        "      cv, CV_METHOD = LeavePOut(2), \"Leave-pair-out\"\n",
        "    elif 50 < NUMBER_OF_SAMPLES < 100:\n",
        "      cv, CV_METHOD = LeaveOneOut(), \"Leave-one-out\"\n",
        "    elif 100 < NUMBER_OF_SAMPLES < 1000:\n",
        "      cv, CV_METHOD = StratifiedKFold(n_splits=10), \"10-Folds cv\"\n",
        "    else:\n",
        "      cv, CV_METHOD = StratifiedKFold(n_splits=5), \"5-Folds cv\"\n",
        "\n",
        "    for fold_num, (train_index, test_index) in enumerate(cv.split(X, y)):\n",
        "      current_model = CLFS_METHODS[LEARNING_ALGORITHM]()\n",
        "      if type(X) == pd.DataFrame:\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "      else:\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "      y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "      # Part D - B starts here!\n",
        "      transformer_linear = KernelPCA(kernel='linear')\n",
        "      transformer_rbf = KernelPCA(kernel='rbf')\n",
        "      X_train_transformed_linear = transformer_linear.fit_transform(X_train)\n",
        "      X_train_transformed_rbf = transformer_rbf.fit_transform(X_train)\n",
        "      X_train = np.concatenate((X_train, X_train_transformed_linear, X_train_transformed_rbf), axis=1)\n",
        "\n",
        "      # Part D - C starts here!\n",
        "      X_test_transformed_linear = transformer_linear.transform(X_test)\n",
        "      X_test_transformed_rbf = transformer_rbf.transform(X_test)\n",
        "      X_test = np.concatenate((X_test, X_test_transformed_linear, X_test_transformed_rbf), axis=1)\n",
        "\n",
        "      # Part D - D starts here!\n",
        "      neighbors_limit = min(Counter(y_train).values()) - 1\n",
        "      X_train, y_train = BorderlineSMOTE(k_neighbors=min(neighbors_limit, 5), m_neighbors=min(neighbors_limit, 10), n_jobs=-1).fit_resample(X_train, y_train)\n",
        "\n",
        "      # Part D - E starts here!\n",
        "      PIPELINE_TIME, TEST_TIME, MEASURE_VALUES = evaluate_part_d(X_train, X_test, y_train, y_test, current_model)\n",
        "\n",
        "      # Part D - F starts here!\n",
        "      FOLD = str(fold_num + 1)\n",
        "      write_to_results_part_d(results_file, DATASET_NAME, NUMBER_OF_SAMPLES, ORIGINAL_NUMBER_OF_FEATURES, FILTERING_ALGORITHM, LEARNING_ALGORITHM, NUMBER_OF_FEATURES_SELECTED, CV_METHOD, FOLD, MEASURE_VALUES, PIPELINE_TIME, TEST_TIME)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDAEdfAsJnhI"
      },
      "outputs": [],
      "source": [
        "for ds_group in listdir('Results'):\n",
        "  for ds_name in listdir(f\"Results/{ds_group}\"):\n",
        "    if ds_name not in [\"ayeastCC\", \"west\", \"singh\", \"CSS\", \"PBS\", \"BP\", \"PDX\"]: # Last 4 crash because not enough RAM, first 3 are too large to read as pandas dataframe! :(\n",
        "      results_file_name = f\"Results/{ds_group}/{ds_name}/{ds_name}_res.csv\"\n",
        "      X, y = get_x_y(ds_group, ds_name)\n",
        "      # Run the same preprocessing as we run in Part B\n",
        "      curr_preprocessing = make_pipeline(SimpleImputer(), VarianceThreshold(), PowerTransformer())\n",
        "      REDUCE_FEATURES = X.shape[1] > 1000\n",
        "      if REDUCE_FEATURES:\n",
        "        curr_preprocessing.steps.append(['initial_feature_reducer', SelectKBest(k=1000)])\n",
        "      X_new = curr_preprocessing.fit_transform(X, y)\n",
        "      new_cols = X.columns[curr_preprocessing['initial_feature_reducer'].get_support()] if REDUCE_FEATURES else X.columns\n",
        "      X = pd.DataFrame(X_new, columns=new_cols, index=X.index)\n",
        "\n",
        "      run_part_d(X, y, ds_name, results_file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QBYj0XdKan_"
      },
      "source": [
        "We want to analyze the results - we want to compare the results of part d to the actual results. The code block below handles that!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgAeY8x8KZrh"
      },
      "outputs": [],
      "source": [
        "part_b_won = []\n",
        "part_d_won = []\n",
        "maximum_improved = []\n",
        "\n",
        "for ds_group in listdir('Results'):\n",
        "  for ds_name in listdir(f\"Results/{ds_group}\"):\n",
        "    if ds_name not in [\"ayeastCC\", \"west\", \"singh\", \"CSS\", \"PBS\", \"BP\", \"PDX\"]: # Last 4 crash because not enough RAM, first 3 are too large to read as pandas dataframe! :(\n",
        "      part_b_results = pd.read_csv(f\"Results/{ds_group}/{ds_name}/{ds_name}_res.csv\")\n",
        "      part_d_results = pd.read_csv(f\"Results_PartD/{ds_name}_res_aug.csv\")\n",
        "      for measure in MEASURE_TYPES:\n",
        "        part_b_measure_results = part_b_results[part_b_results[\"Measure Type\"] == measure][\"Measure Value\"]\n",
        "        part_d_measure_results = part_d_results[part_d_results[\"Measure Type\"] == measure][\"Measure Value\"]\n",
        "        part_b_measure_mean = part_b_measure_results.mean()\n",
        "        part_d_measure_mean = part_d_measure_results.mean()\n",
        "        part_b_measure_max = part_b_measure_results.max()\n",
        "        part_d_measure_max = part_d_measure_results.max()\n",
        "        if (part_d_measure_max > part_b_measure_max):\n",
        "          print(f\"Maximum measurement improved!\\nDataset: {ds_name}\\nMeasurement: {measure}\\nPart B max: {part_b_measure_max}\\nPart D max: {part_d_measure_max}\")\n",
        "          maximum_improved.append((ds_name, measure, part_b_measure_max, part_d_measure_max))\n",
        "        if (part_b_measure_mean != 0.0 and (fabs(part_b_measure_mean - part_d_measure_mean) / fabs(part_b_measure_mean)) > 0.075) or (part_b_measure_mean == 0 and fabs(part_d_measure_mean) > 0.05):\n",
        "          print(f\"Relative error of more than 7.5% detected!\\nDataset: {ds_name}\\nMeasurement: {measure}\\nPart B mean: {part_b_measure_mean}\\nPart D mean: {part_d_measure_mean}\\n\\n\")\n",
        "          if part_b_measure_mean > part_d_measure_mean:\n",
        "            part_b_won.append((ds_name, measure, part_b_measure_mean, part_d_measure_mean))\n",
        "          else:\n",
        "            part_d_won.append((ds_name, measure, part_b_measure_mean, part_d_measure_mean))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_UWz4d5QqpD"
      },
      "outputs": [],
      "source": [
        "print(\"Part D won: \\n\" + '\\n'.join([f\"Dataset: {a}, Measure: {b}, Part B: {c}, Part D: {d}\" for (a, b, c, d) in part_d_won]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFi-eN9aRYsh"
      },
      "outputs": [],
      "source": [
        "print(\"Part B won: \\n\" + '\\n'.join([f\"Dataset: {a}, Measure: {b}, Part B: {c}, Part D: {d}\" for (a, b, c, d) in part_b_won]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chySHN35SiFa"
      },
      "outputs": [],
      "source": [
        "print(f\"Part B win count: {len(part_b_won)}\\nPart D win count: {len(part_d_won)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gprWmI2RUNIv"
      },
      "source": [
        "The code block below runs the experiment we've described in our conclusions for part D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3W6_XWITtyG"
      },
      "outputs": [],
      "source": [
        "def run_part_d_analysis_experiemnt(X, y, ds_name, results_file_name):\n",
        "  RESULTS_FILENAME = f\"Results_PartD/{ds_name}_EXP.csv\"\n",
        "  if not exists(RESULTS_FILENAME):\n",
        "    print(f\"Reading file {results_file_name}...\")\n",
        "    res_df = pd.read_csv(results_file_name, header=0)\n",
        "    best_auc_row_idx = res_df[(res_df[\"Measure Type\"] == 'AUC') & (res_df[\"Number of features selected (K)\"] >= 5)][\"Measure Value\"].idxmax()\n",
        "    best_auc_row = res_df.iloc[best_auc_row_idx]\n",
        "    winning_fs = best_auc_row[\"Filtering Algorithm\"]\n",
        "    winning_k = best_auc_row[\"Number of features selected (K)\"]\n",
        "    winning_clf = best_auc_row[\"Learning Algorithm\"]\n",
        "    fs_algo = FS[winning_fs](winning_k)\n",
        "    X_new = fs_algo.fit_transform(X, y)\n",
        "    X = pd.DataFrame(X_new, index=X.index)\n",
        "    part_d(X, y, winning_fs, fs_algo, winning_clf, ds_name, winning_k, RESULTS_FILENAME)\n",
        "\n",
        "\n",
        "for ds_group in listdir('Results'):\n",
        "  for ds_name in listdir(f\"Results/{ds_group}\"):\n",
        "    if ds_name not in [\"ayeastCC\", \"west\", \"singh\", \"CSS\", \"PBS\", \"BP\", \"PDX\"]: # Last 4 crash because not enough RAM, first 3 are too large to read as pandas dataframe! :(\n",
        "      results_file_name = f\"Results/{ds_group}/{ds_name}/{ds_name}_res.csv\"\n",
        "      X, y = get_x_y(ds_group, ds_name)\n",
        "      # Run the same preprocessing as we run in Part B\n",
        "      curr_preprocessing = make_pipeline(SimpleImputer(), VarianceThreshold(), PowerTransformer())\n",
        "      REDUCE_FEATURES = X.shape[1] > 1000\n",
        "      if REDUCE_FEATURES:\n",
        "        curr_preprocessing.steps.append(['initial_feature_reducer', SelectKBest(k=1000)])\n",
        "      X_new = curr_preprocessing.fit_transform(X, y)\n",
        "      new_cols = X.columns[curr_preprocessing['initial_feature_reducer'].get_support()] if REDUCE_FEATURES else X.columns\n",
        "      X = pd.DataFrame(X_new, columns=new_cols, index=X.index)\n",
        "\n",
        "      run_part_d_analysis_experiemnt(X, y, ds_name, results_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4QfHcKQUoZs"
      },
      "outputs": [],
      "source": [
        "part_b_won = []\n",
        "part_d_won = []\n",
        "maximum_improved = []\n",
        "\n",
        "for ds_group in listdir('Results'):\n",
        "  for ds_name in listdir(f\"Results/{ds_group}\"):\n",
        "    if ds_name not in [\"ayeastCC\", \"west\", \"singh\", \"CS\", \"CSS\", \"PBS\", \"BP\", \"PDX\"]: # Last 4 crash because not enough RAM, first 3 are too large to read as pandas dataframe! :(\n",
        "      part_b_results = pd.read_csv(f\"Results/{ds_group}/{ds_name}/{ds_name}_res.csv\")\n",
        "      part_d_results = pd.read_csv(f\"Results_PartD/{ds_name}_EXP.csv\")\n",
        "      for measure in MEASURE_TYPES:\n",
        "        part_b_measure_results = part_b_results[part_b_results[\"Measure Type\"] == measure][\"Measure Value\"]\n",
        "        part_d_measure_results = part_d_results[part_d_results[\"Measure Type\"] == measure][\"Measure Value\"]\n",
        "        part_b_measure_mean = part_b_measure_results.mean()\n",
        "        part_d_measure_mean = part_d_measure_results.mean()\n",
        "        part_b_measure_max = part_b_measure_results.max()\n",
        "        part_d_measure_max = part_d_measure_results.max()\n",
        "        if (part_d_measure_max > part_b_measure_max):\n",
        "          print(f\"Maximum measurement improved!\\nDataset: {ds_name}\\nMeasurement: {measure}\\nPart B max: {part_b_measure_max}\\nPart D max: {part_d_measure_max}\")\n",
        "          maximum_improved.append((ds_name, measure, part_b_measure_max, part_d_measure_max))\n",
        "        if (part_b_measure_mean != 0.0 and (fabs(part_b_measure_mean - part_d_measure_mean) / fabs(part_b_measure_mean)) > 0.075) or (part_b_measure_mean == 0 and fabs(part_d_measure_mean) > 0.05):\n",
        "          print(f\"Relative error of more than 7.5% detected!\\nDataset: {ds_name}\\nMeasurement: {measure}\\nPart B mean: {part_b_measure_mean}\\nPart D mean: {part_d_measure_mean}\\n\\n\")\n",
        "          if part_b_measure_mean > part_d_measure_mean:\n",
        "            part_b_won.append((ds_name, measure, part_b_measure_mean, part_d_measure_mean))\n",
        "          else:\n",
        "            part_d_won.append((ds_name, measure, part_b_measure_mean, part_d_measure_mean))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXOPcGNgUsTR"
      },
      "outputs": [],
      "source": [
        "print(\"Part D won: \\n\" + '\\n'.join([f\"Dataset: {a}, Measure: {b}, Part B: {c}, Part D: {d}\" for (a, b, c, d) in part_d_won]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pt2HxxSsUuzg"
      },
      "outputs": [],
      "source": [
        "print(\"Part B won: \\n\" + '\\n'.join([f\"Dataset: {a}, Measure: {b}, Part B: {c}, Part D: {d}\" for (a, b, c, d) in part_b_won]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "re886BPQUxis"
      },
      "outputs": [],
      "source": [
        "print(\"Maximum improved: \\n\" + '\\n'.join([f\"Dataset: {a}, Measure: {b}, Part B: {c}, Part D: {d}\" for (a, b, c, d) in maximum_improved]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifRKs65_UwnG"
      },
      "outputs": [],
      "source": [
        "print(f\"Part B win count: {len(part_b_won)}\\nPart D win count: {len(part_d_won)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9DCfqstSBZq"
      },
      "source": [
        "# Part E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsuqynFYSDIY"
      },
      "outputs": [],
      "source": [
        "original_algorithm_auc = None\n",
        "suggested_improvement_auc = None\n",
        "\n",
        "for ds_group in listdir('Results'):\n",
        "  for ds_name in listdir(f\"Results/{ds_group}\"):\n",
        "    results_file_name = f\"Results/{ds_group}/{ds_name}/{ds_name}_res.csv\"\n",
        "    res_df = pd.read_csv(results_file_name, header=0)\n",
        "    if original_algorithm_auc is not None:\n",
        "      original_algorithm_auc = np.concatenate((original_algorithm_auc, res_df[(res_df[\"Measure Type\"] == 'AUC') & (res_df[\"Filtering Algorithm\"] == \"CBFS\")][\"Measure Value\"].values))\n",
        "    else:\n",
        "      original_algorithm_auc = res_df[(res_df[\"Measure Type\"] == 'AUC') & (res_df[\"Filtering Algorithm\"] == \"CBFS\")][\"Measure Value\"].values\n",
        "    if suggested_improvement_auc is not None:\n",
        "      suggested_improvement_auc = np.concatenate((suggested_improvement_auc, res_df[(res_df[\"Measure Type\"] == 'AUC') & (res_df[\"Filtering Algorithm\"] == \"New_CBFS\")][\"Measure Value\"].values))\n",
        "    else:\n",
        "      suggested_improvement_auc = res_df[(res_df[\"Measure Type\"] == 'AUC') & (res_df[\"Filtering Algorithm\"] == \"New_CBFS\")][\"Measure Value\"].values\n",
        "  \n",
        "bound = min(len(original_algorithm_auc), len(suggested_improvement_auc))\n",
        "original_algorithm_auc = original_algorithm_auc[:bound]\n",
        "suggested_improvement_auc = suggested_improvement_auc[:bound]\n",
        "friedmanchisquare(original_algorithm_auc, suggested_improvement_auc, np.copy(original_algorithm_auc), np.copy(suggested_improvement_auc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWydjmAK3dnu"
      },
      "outputs": [],
      "source": [
        "posthoc_data = np.array([original_algorithm_auc, suggested_improvement_auc, np.copy(original_algorithm_auc), np.copy(suggested_improvement_auc)])\n",
        "posthoc(posthoc_data.T)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Nom0ICQL6HED",
        "LHWgV2fa6HEK",
        "keJpWUbG6HEN",
        "VBKDg7916HEP",
        "E9DCfqstSBZq"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
